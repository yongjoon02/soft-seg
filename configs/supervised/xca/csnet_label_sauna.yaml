# XCA 데이터셋 - CSNet + SAUNA Transform 학습 설정
tag: sauna

model:
  arch_name: csnet
  in_channels: 1
  learning_rate: 0.0002  # Slightly increased for larger batch size (linear scaling: 0.0001 * 192/128)
  weight_decay: 0.00001
  num_classes: 2
  soft_label: true
  loss_type: bce_l1
  l2_lambda: 0.1
  log_image_enabled: true
  log_image_names:
    - '0000.png'
    - '0010.png'
    - '0019.png'

data:
  name: xca
  train_dir: data/xca_full/train
  val_dir: data/xca_full/val
  test_dir: data/xca_full/test
  crop_size: 320
  train_bs: 32  # Increased batch size for better GPU utilization (adjust based on GPU memory)
  num_samples_per_image: 8
  label_subdir: label_sauna

trainer:
  max_epochs: 400
  accelerator: gpu
  devices: 1
  precision: 32-true  # Keep FP32 for stability (16-mixed causes NaN with TopoLoss)
  log_every_n_steps: 10
  check_val_every_n_epoch: 20
  gradient_clip_val: 0.5  # Stronger gradient clipping
  accumulate_grad_batches: 1  # No gradient accumulation needed with larger batch
