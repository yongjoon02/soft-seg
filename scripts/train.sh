#!/bin/bash
# ë²”ìš© í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
# Usage:
#   # ë°ì´í„°ì…‹ ì „ì²´ í•™ìŠµ (4ê°œ ëª¨ë¸ ë³‘ë ¬)
#   bash scripts/train.sh --data xca --gpus "0,1,2,3"
#
#   # íŠ¹ì • ëª¨ë¸ë§Œ í•™ìŠµ
#   bash scripts/train.sh --data xca --models "csnet,dscnet" --gpus "0,1"
#
#   # ë‹¨ì¼ config í•™ìŠµ
#   bash scripts/train.sh --config configs/supervised/xca/csnet.yaml --gpu 0
#
#   # DDP í•™ìŠµ (ì—¬ëŸ¬ GPUë¡œ 1ê°œ ëª¨ë¸)
#   bash scripts/train.sh --config configs/flow/xca/flow.yaml --ddp --gpus "0,1,2,3"
#
#   # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ í•™ìŠµ
#   bash scripts/train.sh --config configs/flow/xca/flow.yaml --ddp --gpus "0,1,2,3" \
#       --resume experiments/.../checkpoints/last.ckpt

set -e

cd /home/yongjun/soft-seg
source .venv/bin/activate
export PYTHONUNBUFFERED=1  # ì¦‰ì‹œ ë¡œê·¸ flush

# ê¸°ë³¸ê°’
CONFIG=""
DATA=""
MODELS=""
GPU=""
GPUS=""
RESUME=""
DDP=false
DDP_STRATEGY="ddp"
DDP_PRECISION="32-true"  # Default to FP32 for stability (can override with --precision)
LOG_SUFFIX=""  # ë¡œê·¸ íŒŒì¼ëª…ì— ë§ë¶™ì¼ ì ‘ë¯¸ì‚¬ (ì˜ˆ: _01, _02)

# ëª¨ë“  ëª¨ë¸ ëª©ë¡
ALL_MODELS=("csnet" "dscnet" "medsegdiff" "berdiff")

# ì¸ì íŒŒì‹±
while [[ $# -gt 0 ]]; do
    case $1 in
        --config|-c)
            CONFIG="$2"
            shift 2
            ;;
        --data|-d)
            DATA="$2"
            shift 2
            ;;
        --models|-m)
            MODELS="$2"
            shift 2
            ;;
        --gpu|-g)
            GPU="$2"
            shift 2
            ;;
        --gpus)
            GPUS="$2"
            shift 2
            ;;
        --resume|-r)
            RESUME="$2"
            shift 2
            ;;
        --ddp)
            DDP=true
            shift 1
            ;;
        --strategy)
            DDP_STRATEGY="$2"
            shift 2
            ;;
        --precision)
            DDP_PRECISION="$2"
            shift 2
            ;;
        --log-suffix)
            LOG_SUFFIX="$2"
            shift 2
            ;;
        --help|-h)
            echo "Usage:"
            echo "  # ë°ì´í„°ì…‹ ì „ì²´ í•™ìŠµ (4ê°œ ëª¨ë¸ ë³‘ë ¬, ê°ê° ë‹¨ì¼ GPU)"
            echo "  bash scripts/train.sh --data <dataset> --gpus <g1,g2,g3,g4>"
            echo ""
            echo "  # íŠ¹ì • ëª¨ë¸ë§Œ í•™ìŠµ"
            echo "  bash scripts/train.sh --data <dataset> --models <m1,m2> --gpus <g1,g2>"
            echo ""
            echo "  # ë‹¨ì¼ config í•™ìŠµ (ë‹¨ì¼ GPU)"
            echo "  bash scripts/train.sh --config <config.yaml> --gpu <N>"
            echo ""
            echo "  # DDP í•™ìŠµ (ì—¬ëŸ¬ GPUë¡œ 1ê°œ ëª¨ë¸)"
            echo "  bash scripts/train.sh --config <config.yaml> --ddp --gpus <g1,g2,g3>"
            echo ""
            echo "  # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ í•™ìŠµ"
            echo "  bash scripts/train.sh --config <config.yaml> --gpu <N> --resume <ckpt_path>"
            echo ""
            echo "Options:"
            echo "  --data, -d       Dataset (xca, octa500_3m, octa500_6m, rossa)"
            echo "  --models, -m     Models (csnet,dscnet,medsegdiff,berdiff)"
            echo "  --gpus           GPU indices (comma-separated)"
            echo "  --config, -c     Single config file path"
            echo "  --gpu, -g        Single GPU index"
            echo "  --resume, -r     Resume from checkpoint path"
            echo "  --ddp            Enable DDP mode"
            echo "  --strategy       DDP strategy (default: ddp)"
            echo "  --precision      DDP precision (default: 16-mixed)"
            echo "  --log-suffix     Append to log filename (e.g., _01, _02)"
            echo ""
            echo "Examples:"
            echo "  bash scripts/train.sh -d xca --gpus '0,1,2,3'"
            echo "  bash scripts/train.sh -c configs/flow/xca/flow.yaml --ddp --gpus '0,1,2,3'"
            echo "  bash scripts/train.sh -c configs/supervised/xca/csnet.yaml -g 0"
            echo "  bash scripts/train.sh -c configs/flow/xca/flow.yaml --ddp --gpus '0,1,2,3' \\"
            echo "      --resume experiments/.../checkpoints/last.ckpt"
            exit 0
            ;;
        *)
            echo "Unknown option: $1"
            exit 1
            ;;
    esac
done

# ë¡œê·¸ ë””ë ‰í† ë¦¬
LOG_DIR="logs"
mkdir -p "${LOG_DIR}"

# Resume ì˜µì…˜ ì²˜ë¦¬
RESUME_ARG=""
if [[ -n "$RESUME" ]]; then
    if [[ ! -f "$RESUME" ]]; then
        echo "âŒ Checkpoint file not found: $RESUME"
        exit 1
    fi
    RESUME_ARG="--resume ${RESUME}"
    echo "ğŸ“‚ Resuming from: ${RESUME}"
fi

# ============================================================
# Mode 1: DDP í•™ìŠµ (ì—¬ëŸ¬ GPUë¡œ 1ê°œ ëª¨ë¸)
# ============================================================
if ${DDP}; then
    if [[ -z "$CONFIG" ]]; then
        echo "âŒ Error: --config is required with --ddp"
        exit 1
    fi
    
    if [[ -z "$GPUS" ]]; then
        echo "âŒ Error: --gpus is required with --ddp"
        exit 1
    fi
    
    if [[ ! -f "$CONFIG" ]]; then
        echo "âŒ Config file not found: $CONFIG"
        exit 1
    fi
    
    export CUDA_VISIBLE_DEVICES=${GPUS}
    NUM_GPUS=$(echo "${GPUS}" | tr ',' '\n' | wc -l)
    
    CONFIG_NAME=$(basename "${CONFIG%.*}")
    TEMP_LOG_FILE="${LOG_DIR}/${CONFIG_NAME}_ddp_train${LOG_SUFFIX}.log"
    
    echo "============================================================"
    echo "DDP Training"
    echo "============================================================"
    echo "Config:    ${CONFIG}"
    echo "GPUs:      ${GPUS} (${NUM_GPUS} devices)"
    echo "Strategy:  ${DDP_STRATEGY}"
    echo "Precision: ${DDP_PRECISION}"
    echo "Log:       ${TEMP_LOG_FILE} (will be renamed with experiment_id)"
    if [[ -n "$RESUME" ]]; then
        echo "Resume:    ${RESUME}"
    fi
    echo "============================================================"
    echo ""
    
    # DDP í™˜ê²½ë³€ìˆ˜
    export NCCL_P2P_DISABLE=1
    
    TRAIN_CMD="python scripts/train.py --config ${CONFIG} ${RESUME_ARG}"
    
    echo "ğŸš€ Starting DDP training..."
    echo "   Monitor: tail -f ${TEMP_LOG_FILE}"
    echo ""
    
    nohup bash -c "source .venv/bin/activate && \
        CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES} \
        PYTHONUNBUFFERED=1 \
        DDP_DEVICES=-1 \
        DDP_STRATEGY=${DDP_STRATEGY} \
        DDP_PRECISION=${DDP_PRECISION} \
        uv run ${TRAIN_CMD}" > "${TEMP_LOG_FILE}" 2>&1 &
    
    PID=$!
    
    # Wait for experiment_id to appear in log, then rename file
    (
        sleep 5  # Wait for training to start
        for i in {1..90}; do
            if [[ -f "${TEMP_LOG_FILE}" ]]; then
                EXP_ID=$(grep -m 1 "Experiment ID:" "${TEMP_LOG_FILE}" 2>/dev/null | sed 's/.*Experiment ID: //' | tr -d '[:space:]')
                if [[ -n "$EXP_ID" ]]; then
                    FINAL_LOG_FILE="${LOG_DIR}/${CONFIG_NAME}_${EXP_ID}_ddp_train.log"
                    mv "${TEMP_LOG_FILE}" "${FINAL_LOG_FILE}" 2>/dev/null && echo "ğŸ“ Log renamed to: ${FINAL_LOG_FILE}" || true
                    break
                fi
            fi
            sleep 1
        done
    ) &
    echo "   PID: ${PID}"
    echo ""
    echo "============================================================"
    echo "âœ… Training started in background!"
    echo "============================================================"
    echo ""
    echo "Monitor:  tail -f ${TEMP_LOG_FILE}"
    echo "         (Log will be renamed with experiment_id shortly)"
    echo "Stop:     kill ${PID}"
    exit 0
fi

# ============================================================
# Mode 2: ë‹¨ì¼ config í•™ìŠµ (ë‹¨ì¼ GPU)
# ============================================================
if [[ -n "$CONFIG" ]]; then
    if [[ -z "$GPU" ]]; then
        echo "âŒ Error: --gpu is required with --config (or use --ddp --gpus for multi-GPU)"
        exit 1
    fi
    
    if [[ ! -f "$CONFIG" ]]; then
        echo "âŒ Config file not found: $CONFIG"
        exit 1
    fi
    
    CONFIG_NAME=$(basename "${CONFIG%.*}")
    TEMP_LOG_FILE="${LOG_DIR}/${CONFIG_NAME}_train${LOG_SUFFIX}.log"
    
    echo "============================================================"
    echo "Single GPU Training"
    echo "============================================================"
    echo "Config: ${CONFIG}"
    echo "GPU:    ${GPU}"
    echo "Log:    ${TEMP_LOG_FILE} (will be renamed with experiment_id)"
    if [[ -n "$RESUME" ]]; then
        echo "Resume: ${RESUME}"
    fi
    echo "============================================================"
    echo ""
    
    TRAIN_CMD="python scripts/train.py --config ${CONFIG} ${RESUME_ARG}"
    
    echo "ğŸš€ Starting training..."
    echo "   Monitor: tail -f ${TEMP_LOG_FILE}"
    echo ""
    
    nohup bash -c "CUDA_VISIBLE_DEVICES=${GPU} PYTHONUNBUFFERED=1 uv run ${TRAIN_CMD}" > "${TEMP_LOG_FILE}" 2>&1 &
    
    PID=$!
    
    # Wait for experiment_id to appear in log, then rename file
    (
        sleep 5  # Wait for training to start
        for i in {1..90}; do
            if [[ -f "${TEMP_LOG_FILE}" ]]; then
                EXP_ID=$(grep -m 1 "Experiment ID:" "${TEMP_LOG_FILE}" 2>/dev/null | sed 's/.*Experiment ID: //' | tr -d '[:space:]')
                if [[ -n "$EXP_ID" ]]; then
                    FINAL_LOG_FILE="${LOG_DIR}/${CONFIG_NAME}_${EXP_ID}_train.log"
                    mv "${TEMP_LOG_FILE}" "${FINAL_LOG_FILE}" 2>/dev/null && echo "ğŸ“ Log renamed to: ${FINAL_LOG_FILE}" || true
                    break
                fi
            fi
            sleep 1
        done
    ) &
    
    echo "   PID: ${PID}"
    echo ""
    echo "============================================================"
    echo "âœ… Training started in background!"
    echo "============================================================"
    echo ""
    echo "Monitor:  tail -f ${TEMP_LOG_FILE}"
    echo "         (Log will be renamed with experiment_id shortly)"
    echo "Stop:     kill ${PID}"
    exit 0
fi

# ============================================================
# Mode 3: ë°ì´í„°ì…‹ ê¸°ë°˜ ë‹¤ì¤‘ ëª¨ë¸ í•™ìŠµ (ê°ê° ë‹¨ì¼ GPU)
# ============================================================
if [[ -z "$DATA" ]]; then
    echo "âŒ Error: --data, --config, or --ddp is required"
    echo ""
    echo "Usage:"
    echo "  bash scripts/train.sh --data <dataset> --gpus <g1,g2,g3,g4>"
    echo "  bash scripts/train.sh --config <config.yaml> --gpu <N>"
    echo "  bash scripts/train.sh --config <config.yaml> --ddp --gpus <g1,g2,g3>"
    exit 1
fi

if [[ -z "$GPUS" ]]; then
    echo "âŒ Error: --gpus is required with --data"
    echo "Usage: bash scripts/train.sh --data ${DATA} --gpus '0,1,2,3'"
    exit 1
fi

# GPU ë°°ì—´ë¡œ ë³€í™˜
IFS=',' read -ra GPU_ARRAY <<< "$GPUS"
NUM_GPUS=${#GPU_ARRAY[@]}

# ëª¨ë¸ ëª©ë¡ ê²°ì •
if [[ -n "$MODELS" ]]; then
    IFS=',' read -ra MODEL_ARRAY <<< "$MODELS"
else
    MODEL_ARRAY=("${ALL_MODELS[@]}")
fi
NUM_MODELS=${#MODEL_ARRAY[@]}

# GPU ê°œìˆ˜ í™•ì¸
if [[ $NUM_GPUS -lt $NUM_MODELS ]]; then
    echo "âš ï¸  Warning: ${NUM_MODELS} models but only ${NUM_GPUS} GPUs"
    echo "   Models will be queued (sequential when GPU busy)"
fi

echo "============================================================"
echo "Multi-Model Training"
echo "============================================================"
echo "Dataset: ${DATA}"
echo "Models:  ${MODEL_ARRAY[*]}"
echo "GPUs:    ${GPUS}"
echo "============================================================"
echo ""

# Config íŒŒì¼ ì°¾ê¸° í•¨ìˆ˜
get_config() {
    local model=$1
    local data=$2
    
    # Supervised models
    if [[ "$model" == "csnet" || "$model" == "dscnet" ]]; then
        echo "configs/supervised/${data}/${model}.yaml"
    # Diffusion models
    elif [[ "$model" == "medsegdiff" || "$model" == "berdiff" ]]; then
        echo "configs/diffusion/${data}/${model}.yaml"
    # Flow models
    elif [[ "$model" == "flow" || "$model" == "dhariwal_concat_unet" ]]; then
        echo "configs/flow/${data}/flow.yaml"
    else
        echo ""
    fi
}

# í•™ìŠµ ì‹œì‘
PIDS=()
for i in "${!MODEL_ARRAY[@]}"; do
    MODEL="${MODEL_ARRAY[$i]}"
    GPU_IDX=$((i % NUM_GPUS))
    GPU="${GPU_ARRAY[$GPU_IDX]}"
    
    CONFIG=$(get_config "$MODEL" "$DATA")
    
    if [[ -z "$CONFIG" || ! -f "$CONFIG" ]]; then
        echo "âš ï¸  Config not found for ${MODEL} on ${DATA}, skipping..."
        continue
    fi
    
    TEMP_LOG_FILE="${LOG_DIR}/${DATA}_${MODEL}_train.log"
    
    echo "ğŸš€ [${MODEL}] Starting on GPU ${GPU}..."
    echo "   Config: ${CONFIG}"
    echo "   Log: ${TEMP_LOG_FILE} (will be renamed with experiment_id)"
    
    nohup bash -c "CUDA_VISIBLE_DEVICES=${GPU} uv run python scripts/train.py --config ${CONFIG}" > "${TEMP_LOG_FILE}" 2>&1 &
    PIDS+=($!)
    
    # Wait for experiment_id to appear in log, then rename file
    (
        sleep 5  # Wait for training to start
        for i in {1..30}; do
            if [[ -f "${TEMP_LOG_FILE}" ]]; then
                EXP_ID=$(grep -m 1 "Experiment ID:" "${TEMP_LOG_FILE}" 2>/dev/null | sed 's/.*Experiment ID: //' | tr -d '[:space:]')
                if [[ -n "$EXP_ID" ]]; then
                    FINAL_LOG_FILE="${LOG_DIR}/${DATA}_${MODEL}_${EXP_ID}_train.log"
                    mv "${TEMP_LOG_FILE}" "${FINAL_LOG_FILE}" 2>/dev/null && echo "ğŸ“ [${MODEL}] Log renamed to: ${FINAL_LOG_FILE}" || true
                    break
                fi
            fi
            sleep 1
        done
    ) &
    
    sleep 2
done

echo ""
echo "============================================================"
echo "âœ… All training jobs started in background!"
echo "============================================================"
echo ""
echo "PIDs: ${PIDS[*]}"
echo ""
echo "Monitor:"
echo "  tail -f ${LOG_DIR}/${DATA}_*.log"
echo "  watch -n 1 nvidia-smi"
echo ""
echo "Stop all:"
echo "  kill ${PIDS[*]}"
