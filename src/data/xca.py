"""XCA (X-ray Coronary Angiography) ë°ì´í„°ì…‹ ëª¨ë“ˆ

XCA ë°ì´í„°ëŠ” ê´€ìƒë™ë§¥ ì¡°ì˜ìˆ  ì´ë¯¸ì§€ì˜ í˜ˆê´€ ë¶„í•  ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.
X-ray ì´ë¯¸ì§€ëŠ” ScaleIntensitydë¡œ ì •ê·œí™”í•˜ì—¬ [-1, 1] ë²”ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
"""
import autorootcwd
import math
import torch
from typing import Optional

from monai.transforms import (
    Compose,
    EnsureChannelFirstd,
    ScaleIntensityd,
    RandRotated,
    RandCropByPosNegLabeld,
    RandAdjustContrastd,
    RandFlipd,
    RandRotate90d,
    RandSpatialCropd,
)
from src.data.base_dataset import BaseOCTDataset, BaseOCTDataModule
from src.utils.registry import DATASET_REGISTRY


class XCADataset(BaseOCTDataset):
    """XCA ë°ì´í„°ì…‹ (BaseOCTDataset ìƒì†)
    
    ë°ì´í„° êµ¬ì¡°:
        root/
            image/  - ì›ë³¸ X-ray ì´ë¯¸ì§€ (grayscale PNG, 512x512)
            label/  - í˜ˆê´€ ë¶„í•  ë§ˆìŠ¤í¬ (grayscale PNG, 512x512)
    
    X-ray íŠ¹í™” ì²˜ë¦¬:
    - RGB/RGBA â†’ Grayscale ë³€í™˜ (ì²« ë²ˆì§¸ ì±„ë„ë§Œ ì‚¬ìš©)
    - RandRotated: X-ray íŠ¹ì„±ì— ë§ëŠ” ì‘ì€ íšŒì „ (Â±7.5ë„)
    - RandAdjustContrastd: X-ray ëŒ€ë¹„ ì¡°ì •
    """
    
    def get_data_fields(self) -> list[str]:
        """XCAëŠ” imageì™€ labelë§Œ ì‚¬ìš©"""
        return ['image', 'label']
    
    def _create_transforms(self):
        """X-ray íŠ¹í™” transform ìƒì„± (Base ì˜¤ë²„ë¼ì´ë“œ)"""
        # Baseì˜ ê¸°ë³¸ transform ë¨¼ì € ìƒì„±
        super()._create_transforms()
        
        keys = self.fields
        
        # RGBâ†’Grayscale ë³€í™˜ ì¶”ê°€ (X-ray íŠ¹í™”)
        rgb_to_gray = lambda d: {
            **d,
            "image": d["image"][:1] if hasattr(d["image"], "shape") and d["image"].shape[0] > 1 else d["image"],
            "label": d["label"][:1] if hasattr(d["label"], "shape") and d["label"].shape[0] > 1 else d["label"],
        }
        
        # Default transformsì— RGBâ†’Gray ì¶”ê°€
        self.default_transforms = Compose([
            self.default_transforms.transforms[0],  # EnsureChannelFirstd
            rgb_to_gray,  # RGBâ†’Grayscale
            ScaleIntensityd(keys="image", minv=-1.0, maxv=1.0),
            ScaleIntensityd(keys="label", minv=0.0, maxv=1.0),
        ])
        
        # Base augmentationì— X-ray íŠ¹í™” transform ì¶”ê°€
        xray_augments = [
            RandRotated(keys=keys, range_x=(math.pi/24, math.pi/24), 
                       range_y=(math.pi/24, math.pi/24), prob=0.25),
            RandAdjustContrastd(keys="image", prob=0.25, gamma=(0.9, 1.1)),
        ]
        
        # ê¸°ì¡´ augmentation ì•ì— X-ray augmentation ì¶”ê°€
        base_transforms = list(self.augmentation_transforms.transforms)
        self.augmentation_transforms = Compose(base_transforms[:3] + xray_augments + base_transforms[3:])
    
    def __getitem__(self, index):
        """
        Get a sample with X-ray specific post-processing.
        
        Args:
            index: Sample index
            
        Returns:
            dict: Dictionary containing image, label, and metadata
        """
        # Base classì˜ __getitem__ í˜¸ì¶œ
        data = super().__getitem__(index)
        
        # X-ray íŠ¹í™” í›„ì²˜ë¦¬: ì´ë¯¸ì§€ clamp (augmentation í›„ ë²”ìœ„ ë²—ì–´ë‚  ìˆ˜ ìˆìŒ)
        if self.augmentation:
            data["image"] = torch.clamp(data["image"], -1.0, 1.0)
        
        return data


class XCADataModule(BaseOCTDataModule):
    """XCA ë°ì´í„° ëª¨ë“ˆ (BaseOCTDataModule ìƒì†)
    
    Usage:
        datamodule = XCADataModule(
            train_dir='data/xca_dataset_split/train',
            val_dir='data/xca_dataset_split/val',
            test_dir='data/xca_dataset_split/test',
            crop_size=320,
            train_bs=8,
            num_samples_per_image=1,
        )
    """
    
    dataset_class = XCADataset
    
    def __init__(
        self,
        train_dir: str = 'data/xca_dataset_split/train',
        val_dir: str = 'data/xca_dataset_split/val',
        test_dir: Optional[str] = 'data/xca_dataset_split/test',
        crop_size: int = 320,
        train_bs: int = 8,
        num_samples_per_image: int = 1,
    ):
        """XCA ë°ì´í„° ëª¨ë“ˆ ì´ˆê¸°í™”
        
        Args:
            train_dir: í•™ìŠµ ë°ì´í„° ë””ë ‰í† ë¦¬
            val_dir: ê²€ì¦ ë°ì´í„° ë””ë ‰í† ë¦¬
            test_dir: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í† ë¦¬ (ì„ íƒ)
            crop_size: í¬ë¡­ í¬ê¸° (default: 320, ì›ë³¸ 512Ã—512ì˜ 62.5%)
            train_bs: í•™ìŠµ ë°°ì¹˜ í¬ê¸°
            num_samples_per_image: ì´ë¯¸ì§€ë‹¹ í¬ë¡­ ìƒ˜í”Œ ìˆ˜
        """
        super().__init__(
            train_dir=train_dir,
            val_dir=val_dir,
            test_dir=test_dir,
            crop_size=crop_size,
            train_bs=train_bs,
            num_samples_per_image=num_samples_per_image,
            name='xca'
        )
    
    def create_train_dataset(self):
        """Create training dataset from single directory"""
        return self.dataset_class(
            self.train_dir,
            augmentation=True,
            crop_size=self.crop_size,
            num_samples_per_image=self.num_samples_per_image
        )


@DATASET_REGISTRY.register(name='xca')
class XCA_DataModule(XCADataModule):
    """Registryì— ë“±ë¡ëœ XCA ë°ì´í„° ëª¨ë“ˆ (ê¸°ë³¸ íŒŒë¼ë¯¸í„°)"""
    def __init__(
        self,
        train_dir: str = 'data/xca_dataset_split/train',
        val_dir: str = 'data/xca_dataset_split/val',
        test_dir: Optional[str] = 'data/xca_dataset_split/test',
        crop_size: int = 320,
        train_bs: int = 8,
        num_samples_per_image: int = 1,
    ):
        super().__init__(
            train_dir=train_dir,
            val_dir=val_dir,
            test_dir=test_dir,
            crop_size=crop_size,
            train_bs=train_bs,
            num_samples_per_image=num_samples_per_image,
        )


if __name__ == '__main__':
    from src.utils.visualize_dataloader import visualize_dataset
    
    print("=" * 60)
    print("XCA ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ (BaseOCTDataset ìƒì†)")
    print("=" * 60)
    
    # Registryì—ì„œ ê°€ì ¸ì˜¤ê¸°
    dm = DATASET_REGISTRY.get('xca')()
    dm.setup()
    
    # ë°ì´í„° ê°œìˆ˜ í™•ì¸
    print(f"\nğŸ“Š ë°ì´í„° ê°œìˆ˜:")
    print(f"   Train: {len(dm.train_dataset)} ìƒ˜í”Œ")
    print(f"   Val:   {len(dm.val_dataset)} ìƒ˜í”Œ")
    if dm.test_dataset:
        print(f"   Test:  {len(dm.test_dataset)} ìƒ˜í”Œ")
    
    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
    train_sample = dm.train_dataset[0]
    print(f"\nğŸ“¦ ìƒ˜í”Œ ë°ì´í„° shape:")
    print(f"   Image: {train_sample['image'].shape} (range: {train_sample['image'].min():.2f} ~ {train_sample['image'].max():.2f})")
    print(f"   Label: {train_sample['label'].shape} (range: {train_sample['label'].min():.2f} ~ {train_sample['label'].max():.2f})")
    
    # ì‹œê°í™”
    visualize_dataset(dm.train_dataloader(), "xca_train", num_samples=10)
    visualize_dataset(dm.val_dataloader(), "xca_val")
    if dm.test_dataset:
        visualize_dataset(dm.test_dataloader(), "xca_test")
    
    print("\nâœ… XCA ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
