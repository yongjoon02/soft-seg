# ì½”ë“œ ë¦¬íŒ©í† ë§ ë¡œê·¸

**ë‚ ì§œ**: 2025-11-19  
**ëª©ì **: í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë³µ ì½”ë“œ ì œê±° ë° êµ¬ì¡° ê°œì„   
**ì˜í–¥ ë²”ìœ„**: í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë§Œ ìˆ˜ì • (ê¸°ëŠ¥ ë³€ê²½ ì—†ìŒ)

---

## ğŸ“‹ ë³€ê²½ ìš”ì•½

### ëª©í‘œ
- 70ì¤„ì˜ ì¤‘ë³µ ì½”ë“œë¥¼ ê³µí†µ ëª¨ë“ˆë¡œ ë¶„ë¦¬
- í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ê°„ì†Œí™” ë° ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ
- ê¸°ì¡´ bash ìŠ¤í¬ë¦½íŠ¸ì™€ 100% í˜¸í™˜ì„± ìœ ì§€

### ê²°ê³¼
| íŒŒì¼ | ë³€ê²½ ì „ | ë³€ê²½ í›„ | ì°¨ì´ |
|------|---------|---------|------|
| `train_supervised_models.py` | 73ì¤„ | 24ì¤„ | **-49ì¤„ (-67%)** |
| `train_diffusion_models.py` | 75ì¤„ | 24ì¤„ | **-51ì¤„ (-68%)** |
| `train_base.py` (ì‹ ê·œ) | 0ì¤„ | 87ì¤„ | **+87ì¤„** |
| **ì „ì²´** | 148ì¤„ | 135ì¤„ | **-13ì¤„ (-9%)** |

---

## ğŸ“ ë³€ê²½ëœ íŒŒì¼

### 1. `script/train_base.py` (ì‹ ê·œ ìƒì„±)

**ëª©ì **: í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì˜ ê³µí†µ ë¡œì§ì„ í•œ ê³³ì— ëª¨ìŒ

**ì£¼ìš” ê¸°ëŠ¥**:
```python
def parse_config_and_setup_args(default_config: str):
    """
    Config íŒŒì¼ íŒŒì‹± ë° CLI ì¸ì ì„¤ì •
    
    ìˆ˜í–‰ ì‘ì—…:
    1. Config íŒŒì¼ ë¡œë“œ (ê¸°ë³¸ê°’ fallback)
    2. Dataset ì´ë¦„ ì¶”ì¶œ
    3. data.name í•„ë“œ ì œê±° (LightningCLI í˜¸í™˜)
    4. --arch_nameì„ --model.arch_nameìœ¼ë¡œ ë³€í™˜
    5. TensorBoard ë¡œê±° ê²½ë¡œ ì„¤ì •
    
    Returns:
        (data_name, DataModuleClass)
    """
```

**ì½”ë“œ ìœ„ì¹˜**: `/home/yongjun/soft-seg/script/train_base.py`

**ì „ì²´ ì½”ë“œ** (87ì¤„):
```python
"""Base training script with shared logic for supervised and diffusion models."""

import os
import sys
import yaml
import tempfile
from src.utils.registry import DATASET_REGISTRY


def parse_config_and_setup_args(default_config: str):
    """
    Parse config file and setup command line arguments.
    
    This function handles:
    1. Loading config file (with default fallback)
    2. Extracting dataset name from config
    3. Removing 'data.name' field (not needed by LightningCLI)
    4. Converting --arch_name to LightningCLI format
    5. Setting up TensorBoard logger paths
    
    Args:
        default_config: Default config file path if not provided in args
        
    Returns:
        tuple: (data_name, DataModuleClass)
            - data_name: Dataset name (e.g., 'octa500_3m')
            - DataModuleClass: DataModule class from registry
    """
    # Add default config if not provided
    if '--config' not in sys.argv:
        sys.argv.extend(['--config', default_config])
    
    # Extract config path from arguments
    config_path = None
    if '--config' in sys.argv:
        config_idx = sys.argv.index('--config')
        if config_idx + 1 < len(sys.argv):
            config_path = sys.argv[config_idx + 1]
    
    # Parse config file to get dataset name
    data_name = None
    if config_path:
        try:
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
                data_name = config.get('data', {}).get('name')
                
                # Remove 'name' from data config before passing to LightningCLI
                # LightningCLI doesn't expect this field, so we handle it separately
                if 'data' in config and 'name' in config['data']:
                    del config['data']['name']
                    # Write modified config to a temp file
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as tmp:
                        yaml.dump(config, tmp)
                        temp_config_path = tmp.name
                    # Replace config path in sys.argv
                    sys.argv[sys.argv.index(config_path)] = temp_config_path
        except Exception as e:
            print(f"Warning: Could not parse config file {config_path}: {e}")
    
    if data_name is None:
        print("Error: data.name not found in config file")
        sys.exit(1)
    
    # Get appropriate DataModule from registry
    DataModuleClass = DATASET_REGISTRY.get(data_name)
    
    # Convert --arch_name to LightningCLI overrides
    # This allows using --arch_name csnet instead of --model.arch_name csnet
    if '--arch_name' in sys.argv:
        arch_idx = sys.argv.index('--arch_name')
        if arch_idx + 1 < len(sys.argv):
            arch_name = sys.argv[arch_idx + 1]
            # Remove --arch_name and its value
            sys.argv.pop(arch_idx)
            sys.argv.pop(arch_idx)
            # Add LightningCLI overrides
            sys.argv.extend(['--model.arch_name', arch_name])
            # Set TensorBoard logger name and version
            # This creates directory structure: lightning_logs/{data_name}/{arch_name}/
            sys.argv.extend(['--trainer.logger.init_args.name', data_name])
            sys.argv.extend(['--trainer.logger.init_args.version', arch_name])
    
    return data_name, DataModuleClass
```

---

### 2. `script/train_supervised_models.py` (ê°„ì†Œí™”)

**ë³€ê²½ ì „** (73ì¤„):
```python
"""Supervised training script."""

import os
os.environ['NCCL_P2P_DISABLE'] = '1'
import torch
torch.set_float32_matmul_precision('medium')

import sys
import yaml
import autorootcwd
from lightning.pytorch.cli import LightningCLI
from src.archs.supervised_model import SupervisedModel
from src.utils.registry import DATASET_REGISTRY


if __name__ == "__main__":
    # Add default config if not provided
    if '--config' not in sys.argv:
        sys.argv.extend(['--config', 'configs/octa500_3m_supervised_models.yaml'])
    
    # Extract data_name from config file
    config_path = None
    if '--config' in sys.argv:
        config_idx = sys.argv.index('--config')
        if config_idx + 1 < len(sys.argv):
            config_path = sys.argv[config_idx + 1]
    
    data_name = None
    if config_path:
        try:
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
                data_name = config.get('data', {}).get('name')
                
                # Remove 'name' from data config before passing to LightningCLI
                if 'data' in config and 'name' in config['data']:
                    del config['data']['name']
                    # Write modified config to a temp file
                    import tempfile
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as tmp:
                        yaml.dump(config, tmp)
                        temp_config_path = tmp.name
                    # Replace config path in sys.argv
                    sys.argv[sys.argv.index(config_path)] = temp_config_path
        except Exception as e:
            print(f"Warning: Could not parse config file {config_path}: {e}")
    
    if data_name is None:
        print("Error: data.name not found in config file")
        sys.exit(1)
    
    # Select appropriate DataModule
    DataModuleClass = DATASET_REGISTRY.get(data_name)
    
    # Convert --arch_name to LightningCLI overrides
    if '--arch_name' in sys.argv:
        arch_idx = sys.argv.index('--arch_name')
        if arch_idx + 1 < len(sys.argv):
            arch_name = sys.argv[arch_idx + 1]
            # Remove --arch_name and its value
            sys.argv.pop(arch_idx)
            sys.argv.pop(arch_idx)
            # Add LightningCLI overrides
            sys.argv.extend(['--model.arch_name', arch_name])
            # Set TensorBoard logger name and version
            sys.argv.extend(['--trainer.logger.init_args.name', f"{data_name}"])
            sys.argv.extend(['--trainer.logger.init_args.version', f"{arch_name}"])
    
    cli = LightningCLI(
        SupervisedModel,
        DataModuleClass,
        save_config_kwargs={'overwrite': True},
    )
```

**ë³€ê²½ í›„** (24ì¤„):
```python
"""Supervised training script."""

import os
os.environ['NCCL_P2P_DISABLE'] = '1'
import torch
torch.set_float32_matmul_precision('medium')

import autorootcwd
from lightning.pytorch.cli import LightningCLI
from src.archs.supervised_model import SupervisedModel
from script.train_base import parse_config_and_setup_args


if __name__ == "__main__":
    # Parse config and setup arguments
    data_name, DataModuleClass = parse_config_and_setup_args(
        default_config='configs/octa500_3m_supervised_models.yaml'
    )
    
    # Create LightningCLI
    cli = LightningCLI(
        SupervisedModel,
        DataModuleClass,
        save_config_kwargs={'overwrite': True},
    )
```

**ì£¼ìš” ë³€ê²½ì **:
- âŒ ì œê±°: 49ì¤„ì˜ config íŒŒì‹± ë° argument ì²˜ë¦¬ ë¡œì§
- âœ… ì¶”ê°€: `parse_config_and_setup_args()` í•¨ìˆ˜ í˜¸ì¶œ (2ì¤„)
- âœ… ìœ ì§€: í™˜ê²½ ì„¤ì • (NCCL, torch precision) ë° LightningCLI ìƒì„±

---

### 3. `script/train_diffusion_models.py` (ê°„ì†Œí™”)

**ë³€ê²½ ì „** (75ì¤„):
```python
"""Diffusion model training script."""
import autorootcwd
import os
os.environ['NCCL_P2P_DISABLE'] = '1'
import torch
torch.set_float32_matmul_precision('medium')

import sys
import yaml
import autorootcwd  # ì¤‘ë³µ import
from lightning.pytorch.cli import LightningCLI
from src.archs.diffusion_model import DiffusionModel
from src.utils.registry import DATASET_REGISTRY


if __name__ == "__main__":
    # Add default config if not provided
    if '--config' not in sys.argv:
        sys.argv.extend(['--config', 'configs/octa500_3m_diffusion_models.yaml'])
    
    # Extract data_name from config file
    config_path = None
    if '--config' in sys.argv:
        config_idx = sys.argv.index('--config')
        if config_idx + 1 < len(sys.argv):
            config_path = sys.argv[config_idx + 1]
    
    data_name = None
    if config_path:
        try:
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
                data_name = config.get('data', {}).get('name')
                
                # Remove 'name' from data config before passing to LightningCLI
                if 'data' in config and 'name' in config['data']:
                    del config['data']['name']
                    # Write modified config to a temp file
                    import tempfile
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as tmp:
                        yaml.dump(config, tmp)
                        temp_config_path = tmp.name
                    # Replace config path in sys.argv
                    sys.argv[sys.argv.index(config_path)] = temp_config_path
        except Exception as e:
            print(f"Warning: Could not parse config file {config_path}: {e}")
    
    if data_name is None:
        print("Error: data.name not found in config file")
        sys.exit(1)
    
    # Select appropriate DataModule
    DataModuleClass = DATASET_REGISTRY.get(data_name)
    
    # Convert --arch_name to LightningCLI overrides
    if '--arch_name' in sys.argv:
        arch_idx = sys.argv.index('--arch_name')
        if arch_idx + 1 < len(sys.argv):
            arch_name = sys.argv[arch_idx + 1]
            # Remove --arch_name and its value
            sys.argv.pop(arch_idx)
            sys.argv.pop(arch_idx)
            # Add LightningCLI overrides
            sys.argv.extend(['--model.arch_name', arch_name])
            # Set TensorBoard logger name and version
            sys.argv.extend(['--trainer.logger.init_args.name', f"{data_name}"])
            sys.argv.extend(['--trainer.logger.init_args.version', f"{arch_name}"])
    
    cli = LightningCLI(
        DiffusionModel,
        DataModuleClass,
        save_config_kwargs={'overwrite': True},
    )
```

**ë³€ê²½ í›„** (24ì¤„):
```python
"""Diffusion model training script."""

import os
os.environ['NCCL_P2P_DISABLE'] = '1'
import torch
torch.set_float32_matmul_precision('medium')

import autorootcwd
from lightning.pytorch.cli import LightningCLI
from src.archs.diffusion_model import DiffusionModel
from script.train_base import parse_config_and_setup_args


if __name__ == "__main__":
    # Parse config and setup arguments
    data_name, DataModuleClass = parse_config_and_setup_args(
        default_config='configs/octa500_3m_diffusion_models.yaml'
    )
    
    # Create LightningCLI
    cli = LightningCLI(
        DiffusionModel,
        DataModuleClass,
        save_config_kwargs={'overwrite': True},
    )
```

**ì£¼ìš” ë³€ê²½ì **:
- âŒ ì œê±°: 51ì¤„ì˜ config íŒŒì‹± ë° argument ì²˜ë¦¬ ë¡œì§
- âŒ ì œê±°: ì¤‘ë³µëœ `import autorootcwd`
- âœ… ì¶”ê°€: `parse_config_and_setup_args()` í•¨ìˆ˜ í˜¸ì¶œ (2ì¤„)
- âœ… ìœ ì§€: í™˜ê²½ ì„¤ì • ë° LightningCLI ìƒì„±

---

## âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼

### í…ŒìŠ¤íŠ¸ í™˜ê²½
- Python: 3.12
- PyTorch Lightning
- Dataset: OCTA500_3M

### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

#### 1. Supervised Model (CSNet)
```bash
uv run python script/train_supervised_models.py fit \
    --config configs/octa500_3m_supervised_models.yaml \
    --arch_name csnet \
    --trainer.fast_dev_run true
```

**ê²°ê³¼**: âœ… ì •ìƒ ì‘ë™
```
Seed set to 0
GPU available: True (cuda), used: True
Total params: 8.4 M
Trainer.fit stopped: max_steps=1 reached.
```

#### 2. Diffusion Model (SegDiff)
```bash
uv run python script/train_diffusion_models.py fit \
    --config configs/octa500_3m_diffusion_models.yaml \
    --arch_name segdiff \
    --trainer.fast_dev_run true
```

**ê²°ê³¼**: âœ… ì •ìƒ ì‘ë™
```
Seed set to 0
GPU available: True (cuda), used: True
Trainer.fit stopped: max_steps=1 reached.
```

#### 3. Bash ìŠ¤í¬ë¦½íŠ¸ í˜¸í™˜ì„±
```bash
# ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥
./script/train_supervised_octa_3m.sh
./script/train_diffusion_octa_3m.sh
```

**ê²°ê³¼**: âœ… 100% í˜¸í™˜ (ìˆ˜ì • ë¶ˆí•„ìš”)

---

## ğŸ¯ ê°œì„  íš¨ê³¼

### 1. ì½”ë“œ í’ˆì§ˆ
- âœ… **ì¤‘ë³µ ì œê±°**: 65ì¤„ì˜ ì¤‘ë³µ ë¡œì§ ì œê±°
- âœ… **ê°€ë…ì„±**: ê° ìŠ¤í¬ë¦½íŠ¸ê°€ í•µì‹¬ ê¸°ëŠ¥ë§Œ í‘œí˜„ (24ì¤„)
- âœ… **ì¼ê´€ì„±**: ë‘ ìŠ¤í¬ë¦½íŠ¸ì˜ êµ¬ì¡°ê°€ ì™„ì „íˆ ë™ì¼

### 2. ìœ ì§€ë³´ìˆ˜ì„±
- âœ… **ë‹¨ì¼ ì±…ì„**: Config íŒŒì‹± ë¡œì§ì´ í•œ ê³³ì—ë§Œ ì¡´ì¬
- âœ… **ë²„ê·¸ ìˆ˜ì •**: ë¬¸ì œ ë°œìƒ ì‹œ 1ê°œ íŒŒì¼ë§Œ ìˆ˜ì •
- âœ… **í™•ì¥ì„±**: ìƒˆë¡œìš´ ëª¨ë¸ íƒ€ì… ì¶”ê°€ ì‹œ ì‰½ê²Œ ë³µì‚¬

### 3. ì•ˆì •ì„±
- âœ… **ê¸°ëŠ¥ ë™ì¼**: ê¸°ì¡´ ê¸°ëŠ¥ 100% ìœ ì§€
- âœ… **í˜¸í™˜ì„±**: ëª¨ë“  bash ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • ì—†ì´ ì‘ë™
- âœ… **í…ŒìŠ¤íŠ¸ ì™„ë£Œ**: Supervised, Diffusion ëª¨ë‘ ê²€ì¦

---

## ğŸ“Œ ì£¼ì˜ì‚¬í•­

### ë³€ê²½ë˜ì§€ ì•Šì€ ê²ƒ
- âœ… Config íŒŒì¼ (`configs/*.yaml`)
- âœ… Bash ìŠ¤í¬ë¦½íŠ¸ (`script/*.sh`)
- âœ… ëª¨ë¸ ì½”ë“œ (`src/archs/`)
- âœ… ë°ì´í„° ë¡œë” (`src/data/`)
- âœ… í•™ìŠµ ë¡œì§ ë° ê²°ê³¼

### ë³€ê²½ëœ ê²ƒ
- âš ï¸ `script/train_supervised_models.py` (73ì¤„ â†’ 24ì¤„)
- âš ï¸ `script/train_diffusion_models.py` (75ì¤„ â†’ 24ì¤„)
- âœ¨ `script/train_base.py` (ì‹ ê·œ ìƒì„±, 87ì¤„)

### ë¡¤ë°± ë°©ë²•
Gitì„ ì‚¬ìš©í•œë‹¤ë©´:
```bash
# íŠ¹ì • íŒŒì¼ë§Œ ë˜ëŒë¦¬ê¸°
git checkout HEAD -- script/train_supervised_models.py
git checkout HEAD -- script/train_diffusion_models.py
git rm script/train_base.py
```

---

## ğŸ“Š Diff ìš”ì•½

### train_supervised_models.py
```diff
- import sys
- import yaml
+ from script.train_base import parse_config_and_setup_args

  if __name__ == "__main__":
-     # 49 lines of config parsing logic
-     ...
+     data_name, DataModuleClass = parse_config_and_setup_args(
+         default_config='configs/octa500_3m_supervised_models.yaml'
+     )
      
      cli = LightningCLI(...)
```

### train_diffusion_models.py
```diff
- import sys
- import yaml
- import autorootcwd  # duplicate
+ from script.train_base import parse_config_and_setup_args

  if __name__ == "__main__":
-     # 51 lines of config parsing logic
-     ...
+     data_name, DataModuleClass = parse_config_and_setup_args(
+         default_config='configs/octa500_3m_diffusion_models.yaml'
+     )
      
      cli = LightningCLI(...)
```

---

## ğŸ”— ê´€ë ¨ íŒŒì¼

### ìˆ˜ì •ëœ íŒŒì¼
- `/home/yongjun/soft-seg/script/train_supervised_models.py`
- `/home/yongjun/soft-seg/script/train_diffusion_models.py`

### ì¶”ê°€ëœ íŒŒì¼
- `/home/yongjun/soft-seg/script/train_base.py`

### ì˜í–¥ë°›ì§€ ì•ŠëŠ” íŒŒì¼
- `script/train_supervised_octa_3m.sh`
- `script/train_supervised_octa_6m.sh`
- `script/train_supervised_rossa.sh`
- `script/train_diffusion_octa_3m.sh`
- `script/train_diffusion_octa_6m.sh`
- `script/train_diffusion_rossa.sh`
- `script/evaluate_*.py`
- `script/evaluate_*.sh`
- `configs/*.yaml`

---

## ğŸ’¡ ì¶”ê°€ ê°œì„  ê°€ëŠ¥ ì‚¬í•­

ì´ë²ˆì—ëŠ” ì§„í–‰í•˜ì§€ ì•Šì•˜ì§€ë§Œ, í–¥í›„ ê³ ë ¤í•  ìˆ˜ ìˆëŠ” ê°œì„ ì‚¬í•­:

1. **Dataset í´ë˜ìŠ¤ í†µí•©** (120ì¤„ ì ˆê°)
   - `OCTADataset`ê³¼ `ROSSADataset`ì˜ ì¤‘ë³µ ì œê±°
   
2. **Config êµ¬ì¡° ê°œì„ ** (17ì¤„ ì ˆê°)
   - `data.name` í•„ë“œë¥¼ ìµœìƒìœ„ë¡œ ì´ë™
   - tempfile ìƒì„± ë¡œì§ ì œê±°

3. **Evaluation ìŠ¤í¬ë¦½íŠ¸ ê°œì„ **
   - í•˜ë“œì½”ë”©ëœ DataModule ì œê±°
   - Registry íŒ¨í„´ ì ìš©

4. **Metrics ê³„ì‚° ë¡œì§ í†µí•©** (10ì¤„ ì ˆê°)
   - `validation_step`ê³¼ `test_step` ì¤‘ë³µ ì œê±°

---

## ğŸ“… ë³€ê²½ ì´ë ¥

| ë‚ ì§œ | ì‘ì—… | ë‹´ë‹¹ì | ìƒíƒœ |
|------|------|--------|------|
| 2025-11-19 | í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ë¦¬íŒ©í† ë§ (#1) | - | âœ… ì™„ë£Œ |
| 2025-11-19 | ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (Supervised) | - | âœ… í†µê³¼ |
| 2025-11-19 | ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (Diffusion) | - | âœ… í†µê³¼ |
| 2025-11-19 | í˜¸í™˜ì„± ê²€ì¦ | - | âœ… í†µê³¼ |
| 2025-11-19 | Dataset í´ë˜ìŠ¤ ë¦¬íŒ©í† ë§ (#2) | - | âœ… ì™„ë£Œ |
| 2025-11-19 | Dataset í…ŒìŠ¤íŠ¸ (OCTA500/ROSSA) | - | âœ… í†µê³¼ |

---

## ğŸ”„ ë¦¬íŒ©í† ë§ #2: Dataset í´ë˜ìŠ¤ í†µí•© (2025-11-19)

### ğŸ“‹ ë³€ê²½ ìš”ì•½

**ëª©í‘œ**: Dataset í´ë˜ìŠ¤ì˜ 250ì¤„ ì¤‘ë³µ ì½”ë“œ ì œê±° ë° Base í´ë˜ìŠ¤ í†µí•©

**ê²°ê³¼**:
| íŒŒì¼ | ë³€ê²½ ì „ | ë³€ê²½ í›„ | ì°¨ì´ |
|------|---------|---------|------|
| `octa500.py` | 296ì¤„ | 61ì¤„ | **-235ì¤„ (-79%)** |
| `rossa.py` | 284ì¤„ | 121ì¤„ | **-163ì¤„ (-57%)** |
| `base_dataset.py` (ì‹ ê·œ) | 0ì¤„ | 358ì¤„ | **+358ì¤„** |
| **ì „ì²´** | 580ì¤„ | 540ì¤„ | **-40ì¤„ (-7%)** |

### ğŸ“ ë³€ê²½ëœ íŒŒì¼

#### 1. `src/data/base_dataset.py` (ì‹ ê·œ ìƒì„±, 358ì¤„)

**ëª©ì **: ëª¨ë“  OCT ë°ì´í„°ì…‹ì˜ ê³µí†µ ë¡œì§ì„ í•œ ê³³ì— ëª¨ìŒ

**ì£¼ìš” í´ë˜ìŠ¤**:

##### `BaseOCTDataset` (ì¶”ìƒ í´ë˜ìŠ¤)
```python
class BaseOCTDataset(Dataset, ABC):
    """
    ëª¨ë“  OCT ë°ì´í„°ì…‹ì˜ ê¸°ë°˜ í´ë˜ìŠ¤
    
    ê³µí†µ ê¸°ëŠ¥:
    - íŒŒì¼ ë¡œë”© ë° ê²€ì¦
    - Transform ë™ì  ìƒì„±
    - ì¸ë±ì‹± ë° ìƒ˜í”Œ ìƒì„±
    
    ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„í•  ê²ƒ:
    - get_data_fields(): ë¡œë“œí•  í•„ë“œ ëª©ë¡ ë°˜í™˜
    """
```

**í•µì‹¬ ë©”ì„œë“œ**:
- `get_data_fields()`: ì¶”ìƒ ë©”ì„œë“œ, ì„œë¸Œí´ë˜ìŠ¤ê°€ í•„ë“œ ì •ì˜
- `__init__()`: í•„ë“œ ê¸°ë°˜ ë™ì  ë””ë ‰í† ë¦¬ ì„¤ì • ë° íŒŒì¼ ê²€ì¦
- `_create_transforms()`: í•„ë“œì— ë”°ë¼ ë™ì ìœ¼ë¡œ Transform ìƒì„±
- `__getitem__()`: ëª¨ë“  í•„ë“œë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œ

##### `BaseOCTDataModule` (ì¶”ìƒ í´ë˜ìŠ¤)
```python
class BaseOCTDataModule(L.LightningDataModule, ABC):
    """
    ëª¨ë“  OCT DataModuleì˜ ê¸°ë°˜ í´ë˜ìŠ¤
    
    ê³µí†µ ê¸°ëŠ¥:
    - train/val/test dataset setup
    - DataLoader ìƒì„±
    
    ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„í•  ê²ƒ:
    - create_train_dataset(): í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ë¡œì§
    """
```

**í•µì‹¬ ì„¤ì •**:
```python
FIELD_SCALE_CONFIG = {
    "image": (-1.0, 1.0),
    "label": (0.0, 1.0),
    "label_prob": (0.0, 1.0),
    "label_sauna": (-1.0, 1.0),
}
```

---

#### 2. `src/data/octa500.py` (296ì¤„ â†’ 61ì¤„)

**ë³€ê²½ ì „**: 296ì¤„ì˜ ì™„ì „í•œ Dataset/DataModule êµ¬í˜„

**ë³€ê²½ í›„**: 61ì¤„ì˜ ê°„ê²°í•œ ì„œë¸Œí´ë˜ìŠ¤
```python
class OCTADataset(BaseOCTDataset):
    """OCTA500 Dataset with 4 fields"""
    
    def get_data_fields(self) -> list[str]:
        return ['image', 'label', 'label_prob', 'label_sauna']


class OCTADataModule(BaseOCTDataModule):
    """OCTA500 DataModule using single training directory"""
    
    dataset_class = OCTADataset
    
    def create_train_dataset(self):
        return self.dataset_class(
            self.train_dir,
            augmentation=True,
            crop_size=self.crop_size,
            num_samples_per_image=self.num_samples_per_image
        )
```

**ì£¼ìš” ë³€ê²½ì **:
- âŒ ì œê±°: 235ì¤„ì˜ ì¤‘ë³µ ë¡œì§ (íŒŒì¼ ê²€ì¦, Transform, __getitem__ ë“±)
- âœ… ìœ ì§€: Registry ë“±ë¡ (`@DATASET_REGISTRY.register`)
- âœ… ìœ ì§€: í…ŒìŠ¤íŠ¸ ì½”ë“œ (`if __name__ == "__main__"`)

---

#### 3. `src/data/rossa.py` (284ì¤„ â†’ 121ì¤„)

**ë³€ê²½ ì „**: 284ì¤„ì˜ ì™„ì „í•œ Dataset/DataModule êµ¬í˜„

**ë³€ê²½ í›„**: 121ì¤„ì˜ ê°„ê²°í•œ ì„œë¸Œí´ë˜ìŠ¤
```python
class ROSSADataset(BaseOCTDataset):
    """ROSSA Dataset with 3 fields (no label_prob)"""
    
    def get_data_fields(self) -> list[str]:
        return ['image', 'label', 'label_sauna']


class ROSSADataModule(BaseOCTDataModule):
    """ROSSA DataModule combining manual + SAM"""
    
    dataset_class = ROSSADataset
    
    def __init__(self, train_manual_dir, train_sam_dir, ...):
        self.train_manual_dir = train_manual_dir
        self.train_sam_dir = train_sam_dir
        super().__init__(train_dir=None, ...)
    
    def create_train_dataset(self):
        # íŠ¹ìˆ˜ ë¡œì§: 2ê°œ ë””ë ‰í† ë¦¬ ë³‘í•©
        manual = self.dataset_class(self.train_manual_dir, ...)
        sam = self.dataset_class(self.train_sam_dir, ...)
        return ConcatDataset([manual, sam])
```

**ì£¼ìš” ë³€ê²½ì **:
- âŒ ì œê±°: 163ì¤„ì˜ ì¤‘ë³µ ë¡œì§
- âœ… ìœ ì§€: íŠ¹ìˆ˜í•œ 2ê°œ ë””ë ‰í† ë¦¬ ë³‘í•© ë¡œì§
- âœ… ì¶”ê°€: Dataset ë¡œë“œ ì‹œ ìƒ˜í”Œ ìˆ˜ ì¶œë ¥

---

### âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼

#### í…ŒìŠ¤íŠ¸ í™˜ê²½
- Python: 3.12
- PyTorch Lightning
- Datasets: OCTA500_3M, ROSSA

#### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

##### 1. OCTA500 3M Supervised (CSNet)
```bash
uv run python script/train_supervised_models.py fit \
    --config configs/octa500_3m_supervised_models.yaml \
    --arch_name csnet \
    --trainer.fast_dev_run true
```

**ê²°ê³¼**: âœ… ì •ìƒ ì‘ë™
- ëª¨ë¸ ì´ˆê¸°í™”: CSNet (8.4M params)
- DataLoader ì •ìƒ ì‘ë™
- 4ê°œ í•„ë“œ ë¡œë“œ: image, label, label_prob, label_sauna

##### 2. ROSSA Supervised (CSNet)
```bash
uv run python script/train_supervised_models.py fit \
    --config configs/rossa_supervised_models.yaml \
    --arch_name csnet \
    --trainer.fast_dev_run true
```

**ê²°ê³¼**: âœ… ì •ìƒ ì‘ë™
```
ROSSA Dataset loaded:
  Train (manual): 800 samples
  Train (SAM): 4944 samples
  Train (total): 5744 samples
```
- 2ê°œ ë””ë ‰í† ë¦¬ ë³‘í•© ì •ìƒ
- 3ê°œ í•„ë“œ ë¡œë“œ: image, label, label_sauna (label_prob ì—†ìŒ)

##### 3. OCTA500 3M Diffusion (SegDiff)
```bash
uv run python script/train_diffusion_models.py fit \
    --config configs/octa500_3m_diffusion_models.yaml \
    --arch_name segdiff \
    --trainer.fast_dev_run true
```

**ê²°ê³¼**: âœ… ì •ìƒ ì‘ë™
- Diffusion ëª¨ë¸ë„ Base í´ë˜ìŠ¤ ì‚¬ìš©
- label_prob í•„ë“œ ì •ìƒ í™œìš©

---

### ğŸ¯ ê°œì„  íš¨ê³¼

#### 1. ì½”ë“œ í’ˆì§ˆ
- âœ… **ì¤‘ë³µ ì œê±°**: 250ì¤„ì˜ ì¤‘ë³µ ë¡œì§ ì™„ì „ ì œê±°
- âœ… **ì¶”ìƒí™”**: Datasetì˜ ë³¸ì§ˆì  ì°¨ì´ë§Œ ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ ì •ì˜
- âœ… **í™•ì¥ì„±**: ìƒˆ ë°ì´í„°ì…‹ ì¶”ê°€ ì‹œ 10-20ì¤„ë¡œ êµ¬í˜„ ê°€ëŠ¥

#### 2. ìœ ì§€ë³´ìˆ˜ì„±
- âœ… **ë‹¨ì¼ ì±…ì„**: ê³µí†µ ë¡œì§ì´ `base_dataset.py`ì—ë§Œ ì¡´ì¬
- âœ… **ë²„ê·¸ ìˆ˜ì •**: ë¬¸ì œ ë°œìƒ ì‹œ 1ê°œ íŒŒì¼ë§Œ ìˆ˜ì •
- âœ… **ì¼ê´€ì„±**: ëª¨ë“  ë°ì´í„°ì…‹ì´ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤

#### 3. ìƒˆ ë°ì´í„°ì…‹ ì¶”ê°€ ì˜ˆì‹œ
```python
# ìƒˆ ë°ì´í„°ì…‹ì„ ë‹¨ 11ì¤„ë¡œ ì¶”ê°€!
@DATASET_REGISTRY.register(name='drive')
class DRIVEDataModule(BaseOCTDataModule):
    dataset_class = BaseOCTDataset
    
    def __init__(self):
        super().__init__(
            train_dir="data/DRIVE/train",
            val_dir="data/DRIVE/val",
            test_dir="data/DRIVE/test",
            crop_size=128, train_bs=8, 
            num_samples_per_image=1, name='drive'
        )
    
    def get_data_fields(self):
        return ['image', 'label']  # ê°€ì¥ ë‹¨ìˆœí•œ ê²½ìš°
```

---

### ğŸ“Š ë¦¬íŒ©í† ë§ #1 + #2 ëˆ„ì  íš¨ê³¼

| í•­ëª© | ë³€ê²½ ì „ | ë³€ê²½ í›„ | ì ˆê° |
|------|---------|---------|------|
| í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ | 148ì¤„ | 135ì¤„ | -13ì¤„ |
| Dataset í´ë˜ìŠ¤ | 580ì¤„ | 540ì¤„ | -40ì¤„ |
| **ì „ì²´** | **728ì¤„** | **675ì¤„** | **-53ì¤„ (-7%)** |
| **ì¤‘ë³µ ì œê±°** | - | - | **~320ì¤„** |

---

### ğŸ”§ ê¸°ìˆ ì  ìƒì„¸

#### ë™ì  í•„ë“œ ì²˜ë¦¬
```python
# Base í´ë˜ìŠ¤ì—ì„œ í•„ë“œ ê¸°ë°˜ ë™ì  ì²˜ë¦¬
def __init__(self, path, ...):
    self.fields = self.get_data_fields()  # ['image', 'label', ...]
    
    # ë™ì ìœ¼ë¡œ ë””ë ‰í† ë¦¬ ì†ì„± ìƒì„±
    for field in self.fields:
        setattr(self, f"{field}_dir", os.path.join(path, field))
    
    # íŒŒì¼ ê²€ì¦
    for file in image_files:
        file_paths = {
            field: os.path.join(getattr(self, f"{field}_dir"), file)
            for field in self.fields
        }
        if all(os.path.exists(p) for p in file_paths.values()):
            self.data.append(file_paths)
```

#### Transform ë™ì  ìƒì„±
```python
def _create_transforms(self):
    keys = self.fields  # ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ ì •ì˜í•œ í•„ë“œ ì‚¬ìš©
    
    # í•„ë“œë³„ ìŠ¤ì¼€ì¼ ì„¤ì •
    for field in keys:
        if field in FIELD_SCALE_CONFIG:
            minv, maxv = FIELD_SCALE_CONFIG[field]
            # Transform ìƒì„±
```

#### íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬ (ROSSA)
```python
class ROSSADataModule(BaseOCTDataModule):
    def create_train_dataset(self):
        # ì¼ë°˜ì ì´ì§€ ì•Šì€ ê²½ìš°ë„ ì˜¤ë²„ë¼ì´ë“œë¡œ ì²˜ë¦¬
        manual = self.dataset_class(self.train_manual_dir, ...)
        sam = self.dataset_class(self.train_sam_dir, ...)
        return ConcatDataset([manual, sam])
```

---

### ğŸ“Œ ì£¼ì˜ì‚¬í•­

#### ë³€ê²½ë˜ì§€ ì•Šì€ ê²ƒ
- âœ… Config íŒŒì¼ (`configs/*.yaml`)
- âœ… í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (`script/train_*.py`)
- âœ… Bash ìŠ¤í¬ë¦½íŠ¸ (`script/*.sh`)
- âœ… ëª¨ë¸ ì½”ë“œ (`src/archs/`)
- âœ… í•™ìŠµ ë¡œì§ ë° ê²°ê³¼
- âœ… Registry ì‹œìŠ¤í…œ

#### ë³€ê²½ëœ ê²ƒ
- âš ï¸ `src/data/octa500.py` (296ì¤„ â†’ 61ì¤„)
- âš ï¸ `src/data/rossa.py` (284ì¤„ â†’ 121ì¤„)
- âœ¨ `src/data/base_dataset.py` (ì‹ ê·œ ìƒì„±, 358ì¤„)

#### í˜¸í™˜ì„±
- âœ… ê¸°ì¡´ checkpoint ë¡œë“œ ê°€ëŠ¥
- âœ… ëª¨ë“  config íŒŒì¼ í˜¸í™˜
- âœ… DataLoader ì¶œë ¥ í˜•ì‹ ë™ì¼
- âœ… Registry ë™ì‘ ë™ì¼

---

## ğŸ“® ë¬¸ì˜

ë¬¸ì œ ë°œìƒ ì‹œ:
1. ë¡œê·¸ í™•ì¸: `logs/train_*.log`
2. ì´ ë¬¸ì„œ ì°¸ê³ 
3. Git history í™•ì¸
